{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532edd7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QLoRA fine-tuning script for Qwen3-8B-Instruct using Unsloth.\n",
    "\n",
    "This script fine-tunes the model for structured financial entity extraction\n",
    "from SEC 10-K reports using QLoRA (4-bit quantization + LoRA adapters).\n",
    "\n",
    "Usage:\n",
    "    python -m src.train --output_dir outputs/qwen3-8b-financial-lora\n",
    "    \n",
    "    # Dry run with 2 steps:\n",
    "    python -m src.train --max_steps 2 --output_dir outputs/test_run\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "\n",
    "# Import unsloth first for optimizations\n",
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "from data import load_training_data, QWEN3_CHAT_TEMPLATE\n",
    "\n",
    "\n",
    "# Default configuration\n",
    "DEFAULT_MODEL = \"unsloth/Qwen3-8B-Instruct-unsloth-bnb-4bit\"\n",
    "DEFAULT_OUTPUT_DIR = \"outputs/qwen3-8b-financial-lora\"\n",
    "MAX_SEQ_LENGTH = 8192  # Qwen3 supports up to 32K, but 8K is enough for 10-K excerpts\n",
    "\n",
    "\n",
    "def get_args() -> argparse.Namespace:\n",
    "    \"\"\"Parse command line arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Fine-tune Qwen3-8B-Instruct for financial extraction\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model_name\",\n",
    "        type=str,\n",
    "        default=DEFAULT_MODEL,\n",
    "        help=\"Base model name or path\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        type=str,\n",
    "        default=DEFAULT_OUTPUT_DIR,\n",
    "        help=\"Output directory for LoRA adapter\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=str,\n",
    "        default=\"data/train.jsonl\",\n",
    "        help=\"Path to training data JSONL\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_steps\",\n",
    "        type=int,\n",
    "        default=-1,\n",
    "        help=\"Max training steps (-1 for full epochs)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num_epochs\",\n",
    "        type=int,\n",
    "        default=3,\n",
    "        help=\"Number of training epochs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        type=int,\n",
    "        default=2,\n",
    "        help=\"Per-device batch size\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Gradient accumulation steps\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--learning_rate\",\n",
    "        type=float,\n",
    "        default=2e-4,\n",
    "        help=\"Learning rate\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lora_r\",\n",
    "        type=int,\n",
    "        default=16,\n",
    "        help=\"LoRA rank\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lora_alpha\",\n",
    "        type=int,\n",
    "        default=32,\n",
    "        help=\"LoRA alpha\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--use_wandb\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Enable Weights & Biases logging\"\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(\n",
    "    model_name: str,\n",
    "    lora_r: int = 16,\n",
    "    lora_alpha: int = 32\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Load Qwen3 model with Unsloth optimizations and configure LoRA.\n",
    "    \n",
    "    Args:\n",
    "        model_name: HuggingFace model name or path\n",
    "        lora_r: LoRA rank\n",
    "        lora_alpha: LoRA alpha scaling factor\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (model, tokenizer)\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading model: {model_name}\")\n",
    "    \n",
    "    # Load model with Unsloth's optimizations\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=model_name,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        dtype=None,  # Auto-detect\n",
    "        load_in_4bit=True,\n",
    "    )\n",
    "    \n",
    "    # Configure LoRA adapters\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=lora_r,\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules=[\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "        ],\n",
    "        bias=\"none\",\n",
    "        use_gradient_checkpointing=\"unsloth\",  # Memory optimization\n",
    "        random_state=42,\n",
    "    )\n",
    "    \n",
    "    # Set up chat template for Qwen3\n",
    "    tokenizer = get_chat_template(\n",
    "        tokenizer,\n",
    "        chat_template=\"qwen-2.5\",  # Qwen3 uses same template as Qwen2.5\n",
    "    )\n",
    "    \n",
    "    # Ensure padding token is set\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    logger.info(f\"Model loaded with LoRA: r={lora_r}, alpha={lora_alpha}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples: dict, tokenizer) -> list[str]:\n",
    "    \"\"\"\n",
    "    Format examples for training using the tokenizer's chat template.\n",
    "    \n",
    "    Args:\n",
    "        examples: Batch of examples with 'messages' key\n",
    "        tokenizer: Tokenizer with chat template\n",
    "        \n",
    "    Returns:\n",
    "        List of formatted prompt strings\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for messages in examples[\"messages\"]:\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def train(args: argparse.Namespace):\n",
    "    \"\"\"Main training function.\"\"\"\n",
    "    logger.info(\"Starting QLoRA fine-tuning for financial extraction\")\n",
    "    \n",
    "    # Load model and tokenizer\n",
    "    model, tokenizer = load_model_and_tokenizer(\n",
    "        args.model_name,\n",
    "        lora_r=args.lora_r,\n",
    "        lora_alpha=args.lora_alpha\n",
    "    )\n",
    "    \n",
    "    # Load training data\n",
    "    dataset = load_training_data(args.data_path)\n",
    "    \n",
    "    # Determine reporting settings\n",
    "    if args.use_wandb:\n",
    "        report_to = \"wandb\"\n",
    "        os.environ.setdefault(\"WANDB_PROJECT\", \"financial-extraction\")\n",
    "    else:\n",
    "        report_to = \"none\"\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(args.output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Configure training\n",
    "    training_args = SFTConfig(\n",
    "        output_dir=str(output_dir),\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "        warmup_steps=5,\n",
    "        max_steps=args.max_steps if args.max_steps > 0 else -1,\n",
    "        num_train_epochs=args.num_epochs if args.max_steps <= 0 else 1,\n",
    "        learning_rate=args.learning_rate,\n",
    "        fp16=not model.config.torch_dtype == \"bfloat16\",\n",
    "        bf16=model.config.torch_dtype == \"bfloat16\",\n",
    "        logging_steps=1,\n",
    "        save_strategy=\"epoch\",\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=42,\n",
    "        report_to=report_to,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        packing=False,  # Don't pack sequences for this task\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=dataset,\n",
    "        args=training_args,\n",
    "        formatting_func=lambda ex: formatting_prompts_func(ex, tokenizer),\n",
    "    )\n",
    "    \n",
    "    # Print training info\n",
    "    logger.info(f\"Training dataset size: {len(dataset)}\")\n",
    "    logger.info(f\"Batch size: {args.batch_size}\")\n",
    "    logger.info(f\"Gradient accumulation: {args.gradient_accumulation_steps}\")\n",
    "    logger.info(f\"Effective batch size: {args.batch_size * args.gradient_accumulation_steps}\")\n",
    "    \n",
    "    # Train\n",
    "    logger.info(\"Starting training...\")\n",
    "    trainer_stats = trainer.train()\n",
    "    \n",
    "    # Save the LoRA adapter\n",
    "    logger.info(f\"Saving LoRA adapter to {output_dir}\")\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    # Also save in merged format for easier loading (optional)\n",
    "    merged_dir = output_dir / \"merged\"\n",
    "    if args.max_steps <= 0:  # Only for full training runs\n",
    "        logger.info(f\"Saving merged model to {merged_dir}\")\n",
    "        model.save_pretrained_merged(\n",
    "            str(merged_dir),\n",
    "            tokenizer,\n",
    "            save_method=\"merged_16bit\",\n",
    "        )\n",
    "    \n",
    "    logger.info(\"Training complete!\")\n",
    "    logger.info(f\"Final loss: {trainer_stats.training_loss:.4f}\")\n",
    "    \n",
    "    return trainer_stats\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = get_args()\n",
    "    train(args)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
